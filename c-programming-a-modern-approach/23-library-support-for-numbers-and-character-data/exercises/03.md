# Exercise 3

Check the documentation for your compiler to see if it performs contaction on
arithmetic expressions and, if so, under what circumstances

## Answer

```shell
$ clang -cc1 -help | grep ffp-contract
  -ffp-contract=<value>   Form fused FP ops (e.g. FMAs): fast (fuses across statements disregarding pragmas) | on (only fuses in the same statement unless dictated by pragmas) | off (never fuses) | fast-honor-pragmas (fuses across statements unless diectated by pragmas). Default is 'fast' for CUDA, 'fast-honor-pragmas' for HIP, and 'on' otherwise
```

The default pragma value is `on`.

However, from my machine's `math.h` file

```c
#if defined __arm64__ || defined __ARM_VFPV4__
/*  On these architectures, fma(), fmaf( ), and fmal( ) are generally about as
    fast as (or faster than) separate multiply and add of the same operands.  */
#   define FP_FAST_FMA     1
#   define FP_FAST_FMAF    1
#   define FP_FAST_FMAL    1
#elif (defined __i386__ || defined __x86_64__) && (defined __FMA__ || defined __AVX512F__)
/*  When targeting the FMA ISA extension, fma() and fmaf( ) are generally
    about as fast as (or faster than) separate multiply and add of the same
    operands, but fmal( ) may be more costly.                                 */
#   define FP_FAST_FMA     1
#   define FP_FAST_FMAF    1
#   undef  FP_FAST_FMAL
#else
/*  On these architectures, fma( ), fmaf( ), and fmal( ) function calls are
    significantly more costly than separate multiply and add operations.      */
#   undef  FP_FAST_FMA
#   undef  FP_FAST_FMAF
#   undef  FP_FAST_FMAL
#endif
```

For my machine and clang compiler `__x86_64` is defined, but `__FMA__` is not

```shell
$ clang -dM -E - < /dev/null | grep x86
#define __x86_64 1
#define __x86_64__ 1

$ clang -dM -E - < /dev/null | grep FMA

$
```

So appears might not be as fast as separate multiply and add operations.
